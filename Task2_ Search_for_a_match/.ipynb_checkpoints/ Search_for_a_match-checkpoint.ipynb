{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00b22d8-7985-4dfc-9a5a-7d46033da59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1323d29c-5d67-445c-b99e-cbfd6428f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(audio_path, sr=22050, n_mfcc=13):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b7fff75-4218-42e2-be16-60e3de8409de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_features(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_gray = None\n",
    "    motion_vectors = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if prev_gray is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            motion_vectors.append(np.mean(flow))  # Mean flow per frame\n",
    "\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(motion_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ed296b7-4092-420c-9c09-0adfec38dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def compute_similarity(audio_features, video_features):\n",
    "    # Convert to NumPy arrays and ensure they are 1D\n",
    "    audio_features = np.asarray(audio_features).ravel()\n",
    "    video_features = np.asarray(video_features).ravel()\n",
    "\n",
    "    # Compute DTW distance\n",
    "    distance, _ = fastdtw(audio_features, video_features, dist=euclidean)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da6ada66-8aaf-4a42-aea0-c3de5cc0ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "audio_folder = \"audio_only\"\n",
    "video_folder = \"video_only\"\n",
    "\n",
    "audio_files = sorted(os.listdir(audio_folder))\n",
    "video_files = sorted(os.listdir(video_folder))\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b43ba2c-6f70-4912-8999-890f01a16909",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict = {audio: extract_audio_features(os.path.join(audio_folder, audio)) for audio in audio_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8212885-6efa-46b4-84aa-340e5595a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting video features: 100%|████████████████████████████████████████████████████| 45/45 [1:24:59<00:00, 113.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "video_features_dict = {\n",
    "    video: extract_video_features(os.path.join(video_folder, video))\n",
    "    for video in tqdm(video_files, desc=\"Extracting video features\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d55989-bd8f-41bd-b499-a735731d5087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through each audio file\n",
    "for audio in tqdm(audio_files, desc=\"Matching audio to video\"):\n",
    "    best_match = None\n",
    "    best_score = float(\"inf\")\n",
    "\n",
    "    # Compare with each video file\n",
    "    for video in video_files:\n",
    "        score = compute_similarity(audio_features_dict[audio], video_features_dict[video])\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_match = video\n",
    "\n",
    "    results.append((audio, best_match))\n",
    "\n",
    "# Save results as CSV\n",
    "df = pd.DataFrame(results, columns=[\"audio_file\", \"video_file\"])\n",
    "df.to_csv(\"matched_audio_video.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365dfe1-774f-4814-952c-9ebb29b8fbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd69417-cca1-4d8f-851e-9e3984ccbe83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb460dca-53b3-402d-b9d4-36b082e41220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c620df-0698-408a-9582-e48913c04ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
